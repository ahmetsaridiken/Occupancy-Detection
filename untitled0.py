# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sW_oTtrOE9iLgUOSo2swhrQjgkHs-JvV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve

# Veri setlerini yükleme
data_train = pd.read_csv('/content/datatraining.csv')
data_test1 = pd.read_csv('/content/datatest.csv')
data_test2 = pd.read_csv('/content/datatest2.csv')

# Test veri setlerini birleştirme
data_test = pd.concat([data_test1, data_test2])

# Tarih/saat sütununu kaldırma
data_train = data_train.drop(columns=['date'])
data_test = data_test.drop(columns=['date'])

# Histogram grafiği
data_train.hist(figsize=(15, 10))
plt.suptitle("Histogram of Training Data")
plt.show()

# Korelasyon matrisi
plt.figure(figsize=(10, 8))
corr_matrix = data_train.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Normalizasyon
scaler = MinMaxScaler()
data_train[["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]] = scaler.fit_transform(data_train[["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]])
data_test[["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]] = scaler.transform(data_test[["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]])

# Normalizasyonun ardından veri çerçevesini tekrar oluşturalım
data_train_normalized = pd.DataFrame(scaler.fit_transform(data_train), columns=data_train.columns)
data_test_normalized = pd.DataFrame(scaler.transform(data_test), columns=data_test.columns)

# Normalizasyon Öncesi ve Sonrası Veri
print("Normalizasyon Öncesi Veri:")
print(data_train.head())
print("\nNormalizasyon Sonrası Veri:")
print(data_train_normalized.head())

# Özellik mühendisliği
data_train_normalized['Light_CO2_interaction'] = data_train_normalized['Light'] * data_train_normalized['CO2']
data_test_normalized['Light_CO2_interaction'] = data_test_normalized['Light'] * data_test_normalized['CO2']

# Özellikler (features) ve hedef (target) değişkenlerini ayırma
features = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio', 'Light_CO2_interaction']
X_train = data_train_normalized[features]
y_train = data_train_normalized['Occupancy']
X_test = data_test_normalized[features]
y_test = data_test_normalized['Occupancy']

# Veriyi ölçeklendirme
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Algoritma listesi
algorithms = {
    'Karar Ağacı': DecisionTreeClassifier(),
    'Rastgele Orman': RandomForestClassifier(),
    'K-En Yakın Komşu': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Destek Vektör Makineleri': SVC(probability=True)
}

# Sonuçları saklamak için boş veri çerçevesi
results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])

# Algoritmaları döngüyle çalıştırma
for name, model in algorithms.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Sonuçları ekleme
    results.loc[len(results)] = [name, accuracy, precision, recall, f1]

    # Karışıklık matrisini çizme
    plt.figure(figsize=(6, 4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - Karışıklık Matrisi')
    plt.xlabel('Tahmin Edilen')
    plt.ylabel('Gerçek')
    plt.show()

# Tüm modellerin performans karşılaştırması
print(results)

# ROC eğrisi ve AUC (Area Under the Curve) hesaplama
plt.figure(figsize=(10, 6))
for name, model in algorithms.items():
    model.fit(X_train, y_train)
    y_prob = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    auc = roc_auc_score(y_test, y_prob)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Eğrisi')
plt.legend(loc='lower right')
plt.show()

# Precision-Recall eğrisi hesaplama
plt.figure(figsize=(10, 6))
for name, model in algorithms.items():
    model.fit(X_train, y_train)
    y_prob = model.predict_proba(X_test)[:, 1]
    precision, recall, _ = precision_recall_curve(y_test, y_prob)
    plt.plot(recall, precision, label=f'{name}')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Eğrisi')
plt.legend(loc='upper right')
plt.show()

# Rastgele Orman modeli için hiperparametre ayarlama
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5]
}
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train, y_train)
best_rf = grid_search.best_estimator_

# Çapraz doğrulama
scores = cross_val_score(best_rf, X_train, y_train, cv=5)
print("Ortalama doğruluk (Çapraz Doğrulama):", scores.mean())

# Öznitelik Önemini Görselleştirme
importances = best_rf.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure()
plt.title("Öznitelik Önem Dereceleri")
plt.bar(range(X_train.shape[1]), importances[indices], align="center")
plt.xticks(range(X_train.shape[1]), [features[i] for i in indices], rotation=90)
plt.xlim([-1, X_train.shape[1]])
plt.show()

# Doğruluk oranlarını karşılaştıran çubuk grafik
plt.figure(figsize=(10, 6))
sns.barplot(x='Model', y='Accuracy', data=results)
plt.title('Makine Öğrenmesi Modellerinin Doğruluk Oranları')
plt.xlabel('Model')
plt.ylabel('Doğruluk Oranı')
plt.ylim(0, 1)
plt.show()